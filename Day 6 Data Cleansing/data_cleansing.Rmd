---
title: "Data Cleansing"
output: html_document
---

```{r}
library(readr)
library(dplyr)
#install.packages("assertive")
library(assertive)
```


```{r}
(bike_share_rides <- read.csv('bike_share_rides.csv'))
```


```{r}
# Glimpse at bike_share_rides
glimpse(bike_share_rides)

# Summary of user_birth_year
summary(bike_share_rides$user_birth_year)
```

```{r}
# The user_birth_year column represents groupings of data and should be converted to a factor.
```

```{r}
# Convert user_birth_year to factor: user_birth_year_fct
bike_share_rides <- bike_share_rides %>%
  mutate(user_birth_year_fct = as.factor(user_birth_year))

# Assert user_birth_year_fct is a factor
assert_is_factor(bike_share_rides$user_birth_year_fct)

# Summary of user_birth_year_fct
summary(bike_share_rides$user_birth_year_fct)
```

```{r}
# Glimpse at bike_share_rides
glimpse(bike_share_rides)
```

# Trimming strings
```{r}
library(stringr)
```


```{r}
bike_share_rides <- bike_share_rides %>%
  # Remove 'minutes' from duration: duration_trimmed
  mutate(duration_trimmed = str_remove(duration, "minutes"),
         # Convert duration_trimmed to numeric: duration_mins
         duration_mins = as.numeric(duration_trimmed))

# Glimpse at bike_share_rides
glimpse(bike_share_rides)

# Assert duration_mins is numeric
assert_is_numeric(bike_share_rides$duration_mins)

# Calculate mean duration
mean(bike_share_rides$duration_mins)
```

```{r}
library(ggplot2)
```

# Ride duration constraints
```{r}
# duration_min_const: replace vals of duration_min > 1440 with 1440
bike_share_rides <- bike_share_rides %>%
  mutate(duration_min_const = replace(duration_mins, duration_mins > 1440, 1440))

# Make sure all values of duration_min_const are between 0 and 1440
assert_all_are_in_closed_range(bike_share_rides$duration_min_const, lower = 0, upper = 1440)
```


```{r}
library(lubridate)
# Convert date to Date type
bike_share_rides <- bike_share_rides %>%
  mutate(date = as.Date(date))

# Make sure all dates are in the past
assert_all_are_in_past(bike_share_rides$date)
```

```{r}
# Filter for rides that occurred before or on today's date
bike_share_rides_past <- bike_share_rides %>%
  filter(date <= today())

# Make sure all dates from bike_share_rides_past are in the past
assert_all_are_in_past(bike_share_rides_past$date)
```



# Full duplicates
```{r}
# Count the number of full duplicates
sum(duplicated(bike_share_rides))
```
```{r}
# Remove duplicates
bike_share_rides_unique <- distinct(bike_share_rides)

# Count the full duplicates in bike_share_rides_unique
sum(duplicated(bike_share_rides_unique))
```

# Removing partial duplicates
```{r}
# Find duplicated ride_ids
bike_share_rides %>% 
  # Count the number of occurrences of each ride_id
  count(ride_id) %>% 
  # Filter for rows with a count > 1
  filter(n > 1)
```

```{r}
# Remove full and partial duplicates
bike_share_rides_unique <- bike_share_rides %>%
  # Only based on ride_id instead of all cols
  distinct(ride_id, .keep_all = TRUE)
```

```{r}
# Find duplicated ride_ids in bike_share_rides_unique
bike_share_rides_unique %>%
  # Count the number of occurrences of each ride_id
  count(ride_id) %>%
  # Filter for rows with a count > 1
  filter(n > 1)
```

# Aggregating partial duplicates
```{r}
bike_share_rides %>%
  # Group by ride_id and date
  group_by(ride_id, date) %>%
  # Add duration_min_avg column
  mutate(duration_min_avg = mean(duration_mins)) %>%
  # Remove duplicates based on ride_id and date, keep all cols
  distinct(ride_id, date, .keep_all = TRUE) 
```




# Categorical text data

```{r}
(sfo_survey <- read.csv('sfo_survey.csv'))
```


```{r}
# Count the number of occurrences of dest_size
sfo_survey %>%
  count(dest_size)

## VIOLATING 
# "huge", " Small ", "Large ", and " Hub"
```




# Text data
```{r}
library(stringr)
```

```{r}
# Filter for rows with "-" in the phone column
sfo_survey %>%
  filter(str_detect(phone, "-"))
```


